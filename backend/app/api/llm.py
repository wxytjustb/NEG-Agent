# å¤§æ¨¡å‹è°ƒç”¨
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import StreamingResponse
from app.schemas.agent_schema import WorkflowChatRequest
from app.modules.workflow.workflows.workflow import get_chat_workflow
from app.modules.workflow.core.state import WorkflowState
from app.core.security import get_current_session
import logging
import json

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/agent", tags=["LLM"])


@router.post("/chat1", summary="Workflow å¯¹è¯æ¥å£ï¼ˆåŸºäº LangGraph - æµå¼ï¼‰")
async def chat_with_workflow(request: WorkflowChatRequest, user: dict = Depends(get_current_session)):
    """æµå¼å¯¹è¯ - ä½¿ç”¨ LangGraph çš„ astream_events ç›‘å¬ LLM æµå¼è¾“å‡º"""
    try:
        user_id = user.get("user_id")
        session_id = user.get("session_token")
        
        if not user_id or not session_id:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="æ— æ³•è·å–ç”¨æˆ·ID")
        
        async def sse_generator():
            try:
                logger.info(f"å¼€å§‹ Workflow æµå¼å¯¹è¯: user_id={user_id}")
                logger.info(f"ğŸ” Session æ•°æ®: {user}")
                
                # å‡†å¤‡åˆå§‹çŠ¶æ€
                initial_state: WorkflowState = {
                    "user_input": request.user_input,
                    "session_id": session_id,
                    "history_text": request.history_text or "",
                    "long_term_memory": "",
                    "is_streaming": False,
                    "user_id": user_id
                }
                
                # è·å– workflow
                workflow = get_chat_workflow()
                
                # ä½¿ç”¨ astream_events ç›‘å¬ LLM çš„æµå¼è¾“å‡º
                async for event in workflow.astream_events(initial_state, version="v1"):
                    kind = event["event"]
                    
                    # ç›‘å¬ LLM çš„æµå¼è¾“å‡ºï¼ˆon_chat_model_stream äº‹ä»¶ï¼‰
                    if kind == "on_chat_model_stream":
                        content = event["data"]["chunk"].content
                        if content:
                            yield f"data: {content}\n\n"
                
                logger.info("Workflow æ‰§è¡Œå®Œæˆ")
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                logger.error(f"Workflow æµå¼é”™è¯¯: {str(e)}", exc_info=True)
                yield f"data: [ERROR] {str(e)}\n\n"
                yield "data: [DONE]\n\n"
        
        headers = {"Cache-Control": "no-cache", "Connection": "keep-alive", "X-Accel-Buffering": "no"}
        return StreamingResponse(sse_generator(), media_type="text/event-stream", headers=headers)
        
    except Exception as e:
        logger.error(f"Workflow å¤±è´¥: {str(e)}", exc_info=True)
        async def error_generator():
            yield f"data: [ERROR] {str(e)}\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(error_generator(), media_type="text/event-stream")
