# LLM æ ¸å¿ƒå®¢æˆ·ç«¯ - è´Ÿè´£åˆ›å»º LLM å®ä¾‹
from langchain_openai import ChatOpenAI
from typing import Optional
from app.core.config import settings
from pydantic import SecretStr
import logging

logger = logging.getLogger(__name__)


class LLMCore:
    """LLM æ ¸å¿ƒå®¢æˆ·ç«¯ - è´Ÿè´£åˆ›å»ºå’Œç®¡ç† LLM æ¨¡å‹è¿æ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ– LLM æ ¸å¿ƒå®¢æˆ·ç«¯"""
        # DeepSeek é…ç½®
        self.deepseek_api_key = settings.LLM_API_KEY
        self.deepseek_api_base = settings.LLM_API_BASE_URL
        self.deepseek_model = settings.LLM_MODEL
        
        # éªŒè¯é…ç½®
        self._validate_config()
    
    def _validate_config(self):
        """éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®"""
        if not self.deepseek_api_key:
            logger.warning("LLM_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
        logger.info(f"LLM æ ¸å¿ƒ: ä½¿ç”¨ DeepSeek æ¨¡å‹ {self.deepseek_model}")
    
    def create_llm(
        self, 
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        model: Optional[str] = None,
        provider: Optional[str] = "deepseek"  # ä¿ç•™å‚æ•°ä»¥å…¼å®¹å‰ç«¯ï¼Œé»˜è®¤å€¼ä¸º deepseek
    ) -> ChatOpenAI:
        """åˆ›å»º LLM å®ä¾‹ï¼ˆDeepSeekï¼‰
        
        Args:
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            provider: æä¾›å•†åç§°ï¼ˆä¿ç•™ä»¥å…¼å®¹å‰ç«¯ï¼Œç›®å‰ä»…æ”¯æŒ deepseekï¼‰
            
        Returns:
            ChatOpenAI å®ä¾‹
        """
        # å¿½ç•¥ provider å‚æ•°ï¼Œå§‹ç»ˆåˆ›å»º DeepSeek LLM
        return ChatOpenAI(
            model=model or self.deepseek_model,
            temperature=temperature or 0.7,
            max_tokens=max_tokens or 2000,
            api_key=SecretStr(self.deepseek_api_key) if self.deepseek_api_key else None,  # type: ignore
            base_url=self.deepseek_api_base,
            streaming=True,  # ğŸ”¥ å¯ç”¨æµå¼è¾“å‡º
        )
    
    def get_default_model_name(self) -> str:
        """è·å–é»˜è®¤æ¨¡å‹åç§°
        
        Returns:
            æ¨¡å‹åç§°
        """
        return self.deepseek_model


# åˆ›å»ºå…¨å±€å®ä¾‹
llm_core = LLMCore()
