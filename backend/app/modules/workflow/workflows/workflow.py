from langgraph.graph import END  # type: ignore
from app.modules.workflow.core.graph import WorkflowGraphBuilder
from app.modules.workflow.core.state import WorkflowState, format_workflow_state
from app.modules.workflow.nodes.Intent_recognition import detect_intent
from app.modules.workflow.nodes.llm_answer import async_llm_stream_answer_node
from app.modules.workflow.nodes.ticket_analysis import async_ticket_analysis_node, async_ask_user_confirmation_node
from app.modules.workflow.nodes.user_info import async_user_info_node  # å¼‚æ­¥ç‰ˆæœ¬ï¼ˆæ”¯æŒ session ç¼“å­˜ï¼‰
from app.modules.workflow.nodes.chromadb_node import get_memory_node, save_memory_node  # ChromaDB è®°å¿†èŠ‚ç‚¹
from app.modules.workflow.nodes.database_node import save_database_node  # MySQL æ•°æ®åº“èŠ‚ç‚¹
from app.modules.workflow.nodes.working_memory import working_memory  # Working Memory çŸ­æœŸè®°å¿†èŠ‚ç‚¹
from app.modules.workflow.nodes.feedback_node import async_feedback_node  # ç”¨æˆ·åé¦ˆèŠ‚ç‚¹
# from app.utils.greeting import check_and_respond_greeting, stream_greeting_response  # é—®å€™è¯­æ£€æµ‹å’Œå›å¤ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
from typing import Dict, Any, Optional
from lmnr import observe, Laminar
import logging

logger = logging.getLogger(__name__)


@observe(name="intent_recognition_node", tags=["node", "intent"])
def intent_recognition_node(state: WorkflowState) -> Dict[str, Any]:
    """æ„å›¾è¯†åˆ«èŠ‚ç‚¹ - åŸºäºç”¨æˆ·è¾“å…¥åˆ†ææ„å›¾"""
    logger.info("========== æ„å›¾è¯†åˆ«èŠ‚ç‚¹å¼€å§‹ ===========")
    
    # ğŸ› [DEBUG] æ‰“å°å®Œæ•´ State ä¿¡æ¯
    logger.info("=" * 60)
    logger.info("ğŸ› [intent_recognition] FULL STATE DUMP:")
    try:
        import json
        logger.info(json.dumps(format_workflow_state(state), ensure_ascii=False, indent=2, default=str))
    except Exception:
        logger.info(state)
    logger.info("=" * 60)
    
    try:
        user_input = state.get("user_input", "")
        # ä¼˜å…ˆä½¿ç”¨ working_memory_text (RedisçŸ­æœŸè®°å¿†)
        history_text = state.get("working_memory_text") or state.get("history_text", "")
        
        logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input[:50]}...")
        logger.info(f"å†å²ä¸Šä¸‹æ–‡: {len(history_text)} å­—ç¬¦")
        
        # è°ƒç”¨æ„å›¾è¯†åˆ«ï¼ˆåªä½¿ç”¨ user_input å’Œ history_textï¼‰
        intent, confidence, all_scores, intents = detect_intent(
            user_input=user_input,
            history_text=history_text
        )
        
        logger.info(f"âœ… æ„å›¾è¯†åˆ«å®Œæˆ: {intent} (ç½®ä¿¡åº¦: {confidence:.2f})")
        if len(intents) > 1:
            logger.info(f"ğŸ”€ æ£€æµ‹åˆ°æ··åˆæ„å›¾: {intents}")
        
        # è¿”å›æ›´æ–°çš„çŠ¶æ€
        result = {
            "intent": intent,
            "intent_confidence": confidence,
            "intent_scores": all_scores,
            "intents": intents
        }

        # ğŸ› [DEBUG] æ‰“å°è¾“å‡º State ä¿¡æ¯
        logger.info("=" * 60)
        logger.info("ğŸ› [intent_recognition] OUTPUT STATE UPDATE:")
        try:
            logger.info(json.dumps(result, ensure_ascii=False, indent=2, default=str))
        except Exception:
            logger.info(result)
        logger.info("=" * 60)
        
        return result
        
    except Exception as e:
        error_msg = f"æ„å›¾è¯†åˆ«èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return {
            "intent": "æ—¥å¸¸å¯¹è¯",
            "intent_confidence": 0.0,
            "intent_scores": {},
            "intents": [],
            "error": error_msg
        }


@observe(name="get_working_memory_node", tags=["node", "memory", "redis"])
async def get_working_memory_node(state: WorkflowState) -> Dict[str, Any]:
    """è·å– Working Memory èŠ‚ç‚¹ - ä» Redis è·å–æœ€è¿‘10è½®å¯¹è¯"""
    try:
        conversation_id = state.get("conversation_id")  # æ”¹ä¸ºä½¿ç”¨ conversation_id
        if not conversation_id:
            return {"working_memory_text": "", "working_memory_count": 0}
        
        # è·å–æœ€è¿‘10è½®å¯¹è¯ï¼ˆ20æ¡æ¶ˆæ¯ï¼‰
        messages = await working_memory.get_messages(conversation_id)  # ä½¿ç”¨ conversation_id
        
        if not messages:
            return {"working_memory_text": "", "working_memory_count": 0}
        
        # æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
        memory_lines = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            role_name = "ç”¨æˆ·" if role == "user" else "å®‰ç„¶" if role == "assistant" else role
            memory_lines.append(f"{role_name}ï¼š{content}")
        
        memory_text = "\n".join(memory_lines)
        logger.info(f"âœ… Working Memory è·å–å®Œæˆï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯ï¼ˆconversation_id={conversation_id[:20]}...ï¼‰")
        
        return {
            "working_memory_text": memory_text,
            "working_memory_count": len(messages)
        }
    except Exception as e:
        logger.error(f"è·å– Working Memory å¤±è´¥: {e}", exc_info=True)
        return {"working_memory_text": "", "working_memory_count": 0}


@observe(name="save_working_memory_node", tags=["node", "memory", "redis", "storage"])
async def save_to_working_memory_node(state: WorkflowState) -> Dict[str, Any]:
    """ä¿å­˜åˆ° Working Memory èŠ‚ç‚¹ - å°†å¯¹è¯ä¿å­˜åˆ° Redis"""
    try:
        conversation_id = state.get("conversation_id")  # æ”¹ä¸ºä½¿ç”¨ conversation_id
        user_input = state.get("user_input", "")
        llm_response = state.get("llm_response", "")
        
        if not conversation_id:
            return {"working_memory_saved": False}
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        if user_input:
            await working_memory.save_message(
                session_token=conversation_id,  # ä½¿ç”¨ conversation_id
                role="user",
                content=user_input
            )
        
        # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
        if llm_response:
            await working_memory.save_message(
                session_token=conversation_id,  # ä½¿ç”¨ conversation_id
                role="assistant",
                content=llm_response
            )
        
        logger.info(f"âœ… Working Memory ä¿å­˜å®Œæˆï¼ˆconversation_id={conversation_id[:20]}...ï¼‰")
        return {"working_memory_saved": True}
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ° Working Memory å¤±è´¥: {e}", exc_info=True)
        return {"working_memory_saved": False}


def create_chat_workflow():
    """åˆ›å»ºå¯¹è¯å·¥ä½œæµ"""
    logger.info("æ­£åœ¨åˆ›å»ºå¯¹è¯å·¥ä½œæµ...")
    
    # 1. åˆ›å»ºå›¾æ„å»ºå™¨
    builder = WorkflowGraphBuilder(state_schema=WorkflowState)
    
    # 2. æ·»åŠ èŠ‚ç‚¹ï¼ˆæŒ‰æ‰§è¡Œé¡ºåºï¼‰
    builder.add_node("user_info", async_user_info_node)                    # ç¬¬1æ­¥ï¼šè·å–ç”¨æˆ·ç”»åƒ
    builder.add_node("get_working_memory", get_working_memory_node)        # ç¬¬2æ­¥ï¼šè·å– Working Memoryï¼ˆRedis 10è½®å¯¹è¯ï¼‰
    builder.add_node("get_memory", get_memory_node)                        # ç¬¬3æ­¥ï¼šè·å– ChromaDB å†å²è®°å¿†ï¼ˆç›¸ä¼¼åº¦æ£€ç´¢ï¼‰
    builder.add_node("get_feedback", async_feedback_node)                  # ç¬¬3æ­¥ï¼ˆå¹¶è¡Œï¼‰ï¼šè·å–ç”¨æˆ·åé¦ˆè¶‹åŠ¿
    builder.add_node("intent_recognition", intent_recognition_node)        # ç¬¬4æ­¥ï¼šæ„å›¾è¯†åˆ«
    builder.add_node("ticket_analysis", async_ticket_analysis_node)        # ç¬¬5æ­¥ï¼šå·¥å•åˆ†æï¼ˆå¹¶è¡Œï¼‰
    builder.add_node("llm_answer", async_llm_stream_answer_node)          # ç¬¬5æ­¥ï¼šLLMå›ç­”ï¼ˆå¹¶è¡Œï¼‰
    builder.add_node("ask_user_confirmation", async_ask_user_confirmation_node) # ç¬¬6æ­¥ï¼šå·¥å•ç¡®è®¤
    builder.add_node("save_working_memory", save_to_working_memory_node)  # ç¬¬7æ­¥ï¼šä¿å­˜åˆ° Working Memory
    builder.add_node("save_memory", save_memory_node)                     # ç¬¬8æ­¥ï¼šä¿å­˜åˆ° ChromaDB
    builder.add_node("save_database", save_database_node)                 # ç¬¬9æ­¥ï¼šä¿å­˜åˆ° MySQL
    
    # 3. è®¾ç½®å…¥å£èŠ‚ç‚¹
    builder.set_entry_point("user_info")  # ä»ç”¨æˆ·ä¿¡æ¯è·å–å¼€å§‹
    
    # 4. æ·»åŠ è¾¹ï¼ˆè¿æ¥èŠ‚ç‚¹ï¼‰
    # å¹¶è¡Œæµç¨‹ï¼šç”¨æˆ·ä¿¡æ¯ â†’ (Working Memory + ChromaDBè®°å¿† + åé¦ˆè¶‹åŠ¿ å¹¶è¡Œ) â†’ æ„å›¾è¯†åˆ« â†’ (å·¥å•åˆ†æ + LLMå¯¹è¯ å¹¶è¡Œ) â†’ å·¥å•ç¡®è®¤ â†’ ä¿å­˜Working Memory â†’ (ChromaDB + MySQL å¹¶è¡Œä¿å­˜) â†’ ç»“æŸ
    builder.add_edge("user_info", "get_working_memory")           # ç”¨æˆ·ä¿¡æ¯ â†’ Working Memory
    builder.add_edge("user_info", "get_memory")                   # ç”¨æˆ·ä¿¡æ¯ â†’ ChromaDBï¼ˆå¹¶è¡Œï¼‰
    builder.add_edge("user_info", "get_feedback")                 # ç”¨æˆ·ä¿¡æ¯ â†’ åé¦ˆè¶‹åŠ¿ï¼ˆå¹¶è¡Œï¼‰
    
    builder.add_edge("get_working_memory", "intent_recognition")  # Working Memory â†’ æ„å›¾è¯†åˆ«
    builder.add_edge("get_memory", "intent_recognition")          # ChromaDB â†’ æ„å›¾è¯†åˆ«ï¼ˆä¸‰è·¯æ±‡èšï¼‰
    builder.add_edge("get_feedback", "intent_recognition")        # åé¦ˆè¶‹åŠ¿ â†’ æ„å›¾è¯†åˆ«ï¼ˆä¸‰è·¯æ±‡èšï¼‰
    
    # æ„å›¾è¯†åˆ«åï¼Œå¹¶è¡Œæ‰§è¡Œå·¥å•åˆ†æå’Œ LLM å›ç­”
    builder.add_edge("intent_recognition", "ticket_analysis")     # æ„å›¾è¯†åˆ« â†’ å·¥å•åˆ†æ
    builder.add_edge("intent_recognition", "llm_answer")          # æ„å›¾è¯†åˆ« â†’ LLMå¯¹è¯
    
    # å…³é”®ä¿®æ”¹ï¼šå·¥å•ç¡®è®¤èŠ‚ç‚¹éœ€è¦ç­‰å¾… LLMå›ç­” å’Œ å·¥å•åˆ†æ éƒ½å®Œæˆåæ‰æ‰§è¡Œ
    # è¿™æ ·ç¡®ä¿äº† LLM å›ç­”æµå¼è¾“å‡ºå®Œæ¯•ï¼Œä¸”å·¥å•åˆ¤æ–­ç»“æœå·²å‡ºï¼Œå†å‘ç”¨æˆ·å±•ç¤ºç¡®è®¤ç•Œé¢ï¼ˆå‰ç«¯æ•°æ®ï¼‰
    builder.add_edge("ticket_analysis", "ask_user_confirmation")
    builder.add_edge("llm_answer", "ask_user_confirmation")
    
    # å·¥å•ç¡®è®¤å®Œæˆåï¼Œä¿å­˜åˆ° Working Memory
    builder.add_edge("ask_user_confirmation", "save_working_memory")
    
    builder.add_edge("save_working_memory", "save_memory")        # Working Memory â†’ ä¿å­˜åˆ° ChromaDB
    builder.add_edge("save_working_memory", "save_database")      # Working Memory â†’ ä¿å­˜åˆ° MySQLï¼ˆå¹¶è¡Œï¼‰
    builder.add_edge("save_memory", END)                           # ChromaDBä¿å­˜ â†’ ç»“æŸ
    builder.add_edge("save_database", END)                         # MySQLä¿å­˜ â†’ ç»“æŸ
    
    # 5. éªŒè¯å›¾ç»“æ„
    builder.validate()
    
    # 6. ç¼–è¯‘å›¾
    workflow = builder.compile()
    
    logger.info("âœ… å¯¹è¯å·¥ä½œæµåˆ›å»ºå®Œæˆ (Updated)")
    logger.info("å·¥ä½œæµç»“æ„ï¼šç”¨æˆ·ä¿¡æ¯ â†’ [Working Memory + ChromaDB + åé¦ˆè¶‹åŠ¿] â†’ æ„å›¾è¯†åˆ« â†’ [å·¥å•åˆ†æ + LLMå¯¹è¯] â†’ å·¥å•ç¡®è®¤ â†’ ä¿å­˜Working Memory â†’ [ChromaDB + MySQL] â†’ ç»“æŸ")
    
    return workflow


# å…¨å±€å·¥ä½œæµå®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
_chat_workflow = None


def get_chat_workflow():
    """è·å–å¯¹è¯å·¥ä½œæµå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Returns:
        ç¼–è¯‘åçš„å¯¹è¯å·¥ä½œæµ
    """
    global _chat_workflow
    
    # ä¸´æ—¶å¼ºåˆ¶é‡æ–°åˆ›å»ºï¼ˆè°ƒè¯•ç”¨ï¼‰
    logger.info("ğŸ”„ [è°ƒè¯•] å¼ºåˆ¶é‡æ–°åˆ›å»º Workflow...")
    _chat_workflow = create_chat_workflow()
    
    return _chat_workflow


@observe(name="chat_workflow_stream", tags=["workflow", "chat", "streaming"])
async def run_chat_workflow_streaming(
    user_input: str,
    conversation_id: str,  # æ–°å¢ï¼šå¯¹è¯ID
    session_id: str,
    user_id: Optional[str] = None,
    username: Optional[str] = None,
    access_token: Optional[str] = None,  # æ–°å¢ï¼šAccess Token
    user_confirmed_ticket: Optional[bool] = None  # ç”¨æˆ·ç¡®è®¤åˆ›å»ºå·¥å•
):
    """è¿è¡Œå¯¹è¯å·¥ä½œæµï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
    
    Returns:
        ç”Ÿæˆå™¨ï¼Œyield æµå¼å†…å®¹å’Œæœ€ç»ˆçš„ trace_id
    """
    # âœ… é—®å€™è¯­æ£€æµ‹é€»è¾‘å·²æš‚æ—¶ç¦ç”¨ï¼Œåç»­å†æ·»åŠ 
    # is_greeting, greeting_response = check_and_respond_greeting(user_input)
    # if is_greeting:
    #     logger.info(f"ğŸ‘‹ æ£€æµ‹åˆ°çº¯é—®å€™è¯­ï¼Œç›´æ¥è¿”å›é¢„è®¾å›å¤: {greeting_response}")
    #     async for char in stream_greeting_response(greeting_response):
    #         yield char
    #     await working_memory.save_message(session_token=session_id, role="user", content=user_input)
    #     await working_memory.save_message(session_token=session_id, role="assistant", content=greeting_response)
    #     return
    
    initial_state: WorkflowState = {
        "user_input": user_input,
        "conversation_id": conversation_id,  # æ–°å¢ï¼šä¼ å…¥ conversation_id
        "session_id": session_id,
        "is_streaming": True,
        # æ„å›¾è¯†åˆ«åˆå§‹ä¸ºç©ºï¼ˆå¯¹è¯åæ‰è¿›è¡Œæ„å›¾åˆ†æï¼‰
        "intent": "",
        "intent_confidence": 0.0,
        "intent_scores": {},
        "intents": []
    }
    
    if user_id:
        initial_state["user_id"] = user_id
    
    if access_token:
        initial_state["access_token"] = access_token  # æ–°å¢ï¼šä¼ å…¥ access_token

    # å¦‚æœç”¨æˆ·ç¡®è®¤äº†å·¥å•ï¼Œè®¾ç½® state
    if user_confirmed_ticket is not None:
        initial_state["user_confirmed_ticket"] = user_confirmed_ticket
        logger.info(f"ğŸ“© æ”¶åˆ°ç”¨æˆ·ç¡®è®¤: user_confirmed_ticket={user_confirmed_ticket}")

    # è®¾ç½® Laminar è¿½è¸ªå…ƒæ•°æ®
    if user_id:
        Laminar.set_trace_user_id(str(user_id))
    if session_id:
        Laminar.set_trace_session_id(session_id)
    
    Laminar.set_trace_metadata({
        "username": username or "Unknown",
        "user_id": str(user_id) if user_id else None,
        "session_id": session_id[:20] + "..." if len(session_id) > 20 else session_id,
        "message_preview": user_input[:50] + "..." if len(user_input) > 50 else user_input
    })
    
    config = {
        "metadata": {
            "workflow": "chat_workflow",
            "message": user_input[:50] + "..." if len(user_input) > 50 else user_input,
            "session_id": session_id,
            "user_id": str(user_id) if user_id else None,
            "username": username or "Unknown"
        }
    }
    
    has_output = False
    total_input_tokens = 0
    total_output_tokens = 0
    event_count = 0  # è°ƒè¯•ï¼šç»Ÿè®¡äº‹ä»¶æ•°é‡
    final_state = None  # å­˜å‚¨æœ€ç»ˆçŠ¶æ€

    try:
        async for event in get_chat_workflow().astream_events(initial_state, config=config, version="v2"):
            event_type = event.get("event")
            event_count += 1
            
            # æ¯10ä¸ªäº‹ä»¶è®°å½•ä¸€æ¬¡ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
            if event_count % 10 == 0:
                logger.debug(f"å·²å¤„ç† {event_count} ä¸ªäº‹ä»¶ï¼Œå½“å‰ç±»å‹: {event_type}")
            
            # ç›‘å¬ LLM Token ä½¿ç”¨æƒ…å†µ
            if event_type == "on_chat_model_end":
                output = event.get("data", {}).get("output")
                if output and hasattr(output, 'usage_metadata') and output.usage_metadata:
                    usage = output.usage_metadata
                    total_input_tokens += usage.get('input_tokens', 0)
                    total_output_tokens += usage.get('output_tokens', 0)
                    
                    # æ›´æ–° Laminar Span çš„ Token ç»Ÿè®¡
                    Laminar.set_span_attributes({
                        "llm.usage.input_tokens": total_input_tokens,
                        "llm.usage.output_tokens": total_output_tokens,
                        "llm.usage.total_tokens": total_input_tokens + total_output_tokens
                    })
            
            # å°è¯•ç›‘å¬å¤šç§æµå¼äº‹ä»¶ç±»å‹
            if event_type in ["on_chat_model_stream", "on_llm_stream", "on_chain_stream"]:
                # æ£€æŸ¥äº‹ä»¶ä¿¡æ¯
                event_name = event.get("name", "")
                event_tags = event.get("tags", [])

                # è°ƒè¯•ï¼šæ‰“å°äº‹ä»¶ä¿¡æ¯
                # logger.info(f"ğŸ” æµå¼äº‹ä»¶: name={event_name}, tags={event_tags}")

                # ç›´æ¥è¾“å‡ºæ‰€æœ‰æµå¼äº‹ä»¶ï¼ˆå› ä¸º ticket_analysis ä½¿ç”¨åŒæ­¥è°ƒç”¨ï¼Œä¸ä¼šäº§ç”Ÿæµå¼äº‹ä»¶ï¼‰
                chunk = event.get("data", {}).get("chunk")
                if chunk and hasattr(chunk, "content"):
                    content = chunk.content
                    if content:
                        has_output = True
                        yield content

            # ç›‘å¬å·¥ä½œæµç»“æŸäº‹ä»¶ï¼Œè·å–æœ€ç»ˆçŠ¶æ€
            if event_type == "on_chain_end" and event.get("name") == "LangGraph":
                final_state = event.get("data", {}).get("output")
                logger.info("âœ… æ•è·åˆ°å·¥ä½œæµæœ€ç»ˆçŠ¶æ€")
                
                # ğŸ› [DEBUG] æ‰“å°æœ€ç»ˆ State ä¿¡æ¯
                logger.info("=" * 60)
                logger.info("ğŸ› [workflow] FINAL STATE DUMP:")
                try:
                    import json
                    logger.info(json.dumps(format_workflow_state(final_state), ensure_ascii=False, indent=2, default=str))
                except Exception:
                    logger.info(final_state)
                logger.info("=" * 60)

        logger.info(f"âœ… å·¥ä½œæµå®Œæˆ: äº‹ä»¶æ•°={event_count}, æµå¼è¾“å‡º={has_output}")

        # å¦‚æœæœ‰æœ€ç»ˆçŠ¶æ€ï¼Œå¹¶ä¸”åŒ…å«å·¥å•ç›¸å…³ä¿¡æ¯ï¼Œé€šè¿‡ SSE å‘é€ç»™å‰ç«¯
        if final_state:
            import json
            state_update = {}
            if final_state.get("need_create_ticket"):
                state_update["need_create_ticket"] = True
                state_update["ticket_reason"] = final_state.get("ticket_reason", "")
                state_update["problem_type"] = final_state.get("problem_type", "")
                state_update["title"] = final_state.get("title", "")
                state_update["facts"] = final_state.get("facts", "")
                state_update["user_appeal"] = final_state.get("user_appeal", "")
                state_update["company"] = final_state.get("company", "")
                state_update["ticket_parent_category"] = final_state.get("ticket_parent_category", "")
                
                logger.info(f"ğŸ“¤ å‘é€å·¥å•çŠ¶æ€ç»™å‰ç«¯: {state_update}")
                yield f"[STATE] {json.dumps(state_update, ensure_ascii=False)}"

        # å…œåº•é€»è¾‘ï¼šä»…åœ¨å®Œå…¨æ²¡æœ‰è¾“å‡ºæ—¶è§¦å‘
        if not has_output:
            logger.warning("âš ï¸ æœªæ•è·åˆ°æµå¼è¾“å‡ºï¼Œä½¿ç”¨å…œåº•é€»è¾‘ï¼ˆä¸ä¼šé‡æ–°æ‰§è¡Œå·¥ä½œæµï¼‰")

        # âŒ ä¸è¦é‡æ–°æ‰§è¡Œå·¥ä½œæµï¼åªä»å·²å®Œæˆçš„çŠ¶æ€ä¸­è·å–ç»“æœ
        # è¿™é‡Œçš„é—®é¢˜æ˜¯ï¼šastream_events å·²ç»æ‰§è¡Œå®Œäº†å·¥ä½œæµï¼Œåªæ˜¯æ²¡æœ‰ yield å‡ºæ¥
        # æˆ‘ä»¬åº”è¯¥ä»æœ€ç»ˆçŠ¶æ€è·å–ç»“æœï¼Œè€Œä¸æ˜¯å†æ¬¡ invoke

        # ç”±äº astream_events ä¸è¿”å›æœ€ç»ˆçŠ¶æ€ï¼Œæˆ‘ä»¬åªèƒ½æç¤ºé”™è¯¯
            yield "[æç¤º] æµå¼è¾“å‡ºå¼‚å¸¸ï¼Œè¯·é‡è¯•"

    except Exception as e:
        logger.error(f"æµå¼å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
        yield f"[é”™è¯¯] {str(e)}"